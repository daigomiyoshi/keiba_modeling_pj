{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries in main file\n",
    "import datetime\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException, InvalidSessionIdException\n",
    "\n",
    "from Config import params_config, db_config\n",
    "from ScrapingTools.KeibaLabScraper import RaceInfoScraper\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Libraries in KeibaLabScraper.py\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import copy\n",
    "import urllib3\n",
    "import pymysql\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = params_config.parameters\n",
    "db_params = db_config.db_params\n",
    "con = pymysql.connect(**db_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_chrome_driver(parameters):\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--dns-prefetch-disable')\n",
    "    driver = Chrome(executable_path=parameters['DRIVER_DIR'], chrome_options=chrome_options)\n",
    "    driver.set_page_load_timeout(parameters['PAGE_LOAD_TIMEOUT'])\n",
    "    driver.maximize_window()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = initialize_chrome_driver(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HorseInfoScraper\n",
    "### scraping_horse_info_not_acquired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def _back_chrome_window_for_number_of(times):\n",
    "    for _ in range(times):\n",
    "        driver.back()\n",
    "    return None\n",
    "\n",
    "def _load_target_url_page(target_url):\n",
    "    try:\n",
    "        driver.get(target_url)\n",
    "        print('We could load the URL:', driver.current_url)\n",
    "    except (TimeoutException, urllib3.exceptions.MaxRetryError) as e:\n",
    "        print(e)\n",
    "        driver.refresh()\n",
    "\n",
    "def _make_web_driver_click_by(xpath, verbose=True):\n",
    "    for i in range(parameters['RETRIES_WHEN_WEB_CLICK']):\n",
    "        try:\n",
    "            WebDriverWait(driver, parameters['PAGE_LOAD_TIMEOUT']).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath)))\n",
    "            driver.find_element_by_xpath(xpath).click()\n",
    "        except TimeoutException:\n",
    "            print('Timeout when web_driver_click, so retrying... ({TIME}/{MAX})'.\n",
    "                  format(TIME=i+1, MAX=parameters['RETRIES_WHEN_WEB_CLICK']))\n",
    "            continue\n",
    "        else:\n",
    "            if verbose:\n",
    "                print('We could load the XPATH and now locate in:', driver.current_url)\n",
    "            return None\n",
    "    raise NoSuchElementException\\\n",
    "\n",
    "def _fetchall_query(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        cursor.close()\n",
    "        return fetch_result\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_acquired_href_to_horse(db_params, con):\n",
    "    select_query = '''\n",
    "        SELECT DISTINCT href_to_the_horse\n",
    "        FROM keibalab_race_prior_info_list;\n",
    "    '''\n",
    "    fetch_result = _fetchall_query(select_query)\n",
    "    return list(fetch_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fecth_result = get_not_acquired_href_to_horse(db_params, con)\n",
    "href_to_horse_list = [item[0] for item in fecth_result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "href_to_horse = href_to_horse_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.keibalab.jp/db/horse/2013106098/'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "href_to_horse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We could load the URL: https://www.keibalab.jp/db/horse/2013106098/\n"
     ]
    }
   ],
   "source": [
    "_load_target_url_page(target_url=href_to_horse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
