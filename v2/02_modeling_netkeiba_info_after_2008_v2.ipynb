{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pymysql\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import category_encoders as ce\n",
    "import featuretools as ft\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert\n",
    "from Config import params_config, db_config, queries_config\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 400)\n",
    "pd.set_option('display.max_rows', 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': 'daigo1123',\n",
    "    'database': 'dev_netkeiba',\n",
    "    'port': 3306,\n",
    "    'charset': 'utf8'\n",
    "}\n",
    "con = pymysql.connect(**db_params)\n",
    "parameters = params_config.parameters\n",
    "queries = queries_config.queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Data from DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query, con):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_race_master_data_frame(queries, parameters, con):\n",
    "    race_master_list = _fetchall_and_make_list_by(queries['RACE_MASTER_INFO'], con)\n",
    "    return pd.DataFrame(race_master_list, \n",
    "                                         columns=parameters['DATAFRAME_COL_NAMES']['RACE_MASTER_INFO_COLS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_race_table_result_data_frame(queries, parameters, con):\n",
    "    race_table_result_list = _fetchall_and_make_list_by(queries['RACE_TABLE_RESULT_INFO'], con)\n",
    "    return pd.DataFrame(race_table_result_list, \n",
    "                                         columns=parameters['DATAFRAME_COL_NAMES']['RACE_TABLE_RESULT_INFO_COLS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_race_past_x_result_data_frame(queries, parameters, con):\n",
    "    race_past_x_result_list = _fetchall_and_make_list_by(queries['RACE_PAST_X_RESULT_INFO'], con)\n",
    "    return pd.DataFrame(race_past_x_result_list, \n",
    "                                         columns=parameters['DATAFRAME_COL_NAMES']['RACE_PAST_X_RESULT_INFO_COLS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_master_df = _get_race_master_data_frame(queries, parameters, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_table_result_df = _get_race_table_result_data_frame(queries, parameters, con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_past_x_result_df = _get_race_past_x_result_data_frame(queries, parameters, con)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define index variable and objective variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_race_horse_id(row):\n",
    "    horse_num_str = str(row['horse_num']) if row['horse_num'] >= 10 else '0' + str(row['horse_num'])\n",
    "    return row['race_id'] + '_' + horse_num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_race_table_result_df_idx(df):\n",
    "    df['race_horse_id']= df.apply(_make_race_horse_id, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_table_result_df = preprocess_race_table_result_df_idx(race_table_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_race_horse_past_x_id(row):\n",
    "    horse_num_str = str(row['horse_num']) if row['horse_num'] >= 10 else '0' + str(row['horse_num'])\n",
    "    return row['race_id'] + '_' + horse_num_str + '_' + str(row['past_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_race_past_x_result_df_idx(df):\n",
    "    df['race_horse_id']= df.apply(_make_race_horse_id, axis=1)\n",
    "    df['race_horse_past_x_id']= df.apply(_make_race_horse_past_x_id, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_past_x_result_df = preprocess_race_past_x_result_df_idx(race_past_x_result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _define_target_variable(row, model_type='win', obj_type='odds_or_zero'):\n",
    "    if model_type == 'win' and obj_type == 'odds_or_zero':\n",
    "        if row['arrival_order'] == 1 or row['arrival_sec_diff_from_first'] <= 0.002:\n",
    "            return row['win_odds']\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_target_variable(df):\n",
    "    df['y']= df.apply(_define_target_variable, axis=1, model_type='win', obj_type='odds_or_zero')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_table_result_df = preprocess_target_variable(race_table_result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(race_master_df.shape)\n",
    "race_master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(race_table_result_df.shape)\n",
    "race_table_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(race_past_x_result_df.shape)\n",
    "race_past_x_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ここまでがデータ固有の前処理,　以降はAutoProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {    \n",
    "    'CATEGORICAL_FEATURES_DICT': {\n",
    "        'race_place': 'OrdinalEncoder',\n",
    "        'race_corse_baba': 'OrdinalEncoder',\n",
    "        'race_corse_mawari': 'OrdinalEncoder',\n",
    "        'race_weather': 'OrdinalEncoder',\n",
    "        'race_condition': 'OrdinalEncoder',\n",
    "        'race_dow': 'OrdinalEncoder',\n",
    "        \n",
    "        'href_to_horse': 'LeaveOneOutEncoder',\n",
    "        'horse_sex': 'OrdinalEncoder',\n",
    "        'href_to_jockey': 'LeaveOneOutEncoder',\n",
    "        'href_to_owner': 'LeaveOneOutEncoder'\n",
    "    },\n",
    "    \n",
    "    'FEATURETOOLS_PARAMS': {\n",
    "        'INDEX_COL': {\n",
    "            'RACE_MASTER': ['race_id'],\n",
    "            'RACE_TABLE_RESULT': ['race_id', 'race_horse_id'],\n",
    "            'RACE_PAST_X_RESULT': ['race_horse_id', 'race_horse_past_x_id']\n",
    "        },\n",
    "        'FEATURE_COL': {\n",
    "            'RACE_MASTER': [\n",
    "                'race_round',\n",
    "                'race_kai',\n",
    "                'race_place',\n",
    "                'race_corse_baba',\n",
    "                'race_corse_dist',\n",
    "                'race_corse_mawari',\n",
    "                'race_weather',\n",
    "                'race_condition',\n",
    "                'race_year',\n",
    "                'race_month',\n",
    "                'race_date',\n",
    "                'race_dow',\n",
    "                'starting_hour',\n",
    "                'starting_minutes'\n",
    "            ],\n",
    "            'RACE_TABLE_RESULT': [\n",
    "                'bracket_num',\n",
    "                'href_to_horse',\n",
    "                'horse_age',\n",
    "                'horse_sex',\n",
    "                'weight_penalty',\n",
    "                'href_to_jockey',\n",
    "                'href_to_owner',\n",
    "                'popularity_order',\n",
    "                'win_odds'\n",
    "            ],\n",
    "            'RACE_PAST_X_RESULT': [\n",
    "                'past_x_arrival_order',\n",
    "                'arrival_sec_diff_from_first'\n",
    "            ]\n",
    "        },\n",
    "        'PRIMITIVES': {\n",
    "            'aggregation': ['sum', 'mean', 'std', 'max', 'min', 'count', 'skew'],\n",
    "            'transform': []\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'TRAIN_TEST_SPLIT': {\n",
    "        'INDEX_COL': ['race_id', 'horse_num'],\n",
    "        'EXCLUDE_COL': ['race_id', 'horse_num', 'y'],\n",
    "        'TARGET_COL': 'y',\n",
    "        'CRITERIA_TO_SPLIT_DATA': {'race_master.race_year': 2019, 'race_master.race_month': 3}\n",
    "    }\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding categorical features\n",
    "- 参考URL: https://qiita.com/Hyperion13fleet/items/afa49a84bd5db65ffc31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def encode_category_variables(df, parameters):\n",
    "    for key, value in model_params['CATEGORICAL_FEATURES_DICT'].items():        \n",
    "        if key not in df.columns:\n",
    "            continue\n",
    "        if value == 'OrdinalEncoder':\n",
    "            ce_oe = ce.OrdinalEncoder(cols=key, handle_unknown='impute')\n",
    "            df = ce_oe.fit_transform(df)\n",
    "        elif value == 'OneHotEncoder':\n",
    "            ce_ohe = ce.OneHotEncoder(cols=key, handle_unknown='impute')\n",
    "            df = ce_ohe.fit_transform(df)            \n",
    "        elif value == 'LeaveOneOutEncoder':\n",
    "            ce_looe = ce.LeaveOneOutEncoder(cols=key, handle_unknown='impute')\n",
    "            df = ce_looe.fit_transform(df, y=df[model_params['TARGET_COL_NAME']])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "race_master_df = encode_category_variables(race_master_df, parameters)\n",
    "print(race_master_df.shape)\n",
    "race_master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "race_table_result_df = encode_category_variables(race_table_result_df, parameters)\n",
    "print(race_table_result_df.shape)\n",
    "race_table_result_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_past_x_result_df = encode_category_variables(race_past_x_result_df, parameters)\n",
    "print(race_past_x_result_df.shape)\n",
    "race_past_x_result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engeneering by 'featuretools'\n",
    "- 参考URL <br>\n",
    ": https://qiita.com/Hyperion13fleet/items/4eaca365f28049fe11c7 <br>\n",
    ": https://docs.featuretools.com/en/stable/generated/featuretools.dfs.html#featuretools.dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check the primitives\n",
    "# ft.primitives.list_primitives()\n",
    "# # print(ft.primitives.list_primitives().iloc[4,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_race_horse_id(feature_matrix_df):\n",
    "    def get_race_id(row):\n",
    "        race_id = re.split('_', row['race_horse_id'])[0]\n",
    "        return race_id\n",
    "\n",
    "    def get_horse_num(row):\n",
    "        horse_num = int(re.split('_', row['race_horse_id'])[1])\n",
    "        return horse_num\n",
    "\n",
    "    table_index_df = pd.DataFrame()\n",
    "    table_index_df['race_id'] = pd.DataFrame(feature_matrix_df.index).apply(get_race_id, axis=1)\n",
    "    table_index_df['horse_num'] = pd.DataFrame(feature_matrix_df.index).apply(get_horse_num, axis=1)\n",
    "    return table_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engeneer_features_by_featuretools(model_params):\n",
    "    es = ft.EntitySet(id='netkeiba')\n",
    "    es.entity_from_dataframe(entity_id='race_master', \n",
    "                                                    dataframe=race_master_df[model_params['FEATURETOOLS_PARAMS']['INDEX_COL']['RACE_MASTER'] + \n",
    "                                                                                                      model_params['FEATURETOOLS_PARAMS']['FEATURE_COL']['RACE_MASTER']], \n",
    "                                                    index='race_id')\n",
    "    es.entity_from_dataframe(entity_id='race_table', \n",
    "                                                   dataframe=race_table_result_df[model_params['FEATURETOOLS_PARAMS']['INDEX_COL']['RACE_TABLE_RESULT'] + \n",
    "                                                                                                              model_params['FEATURETOOLS_PARAMS']['FEATURE_COL']['RACE_TABLE_RESULT']], \n",
    "                                                   index='race_horse_id')\n",
    "    es.entity_from_dataframe(entity_id='race_past_x', \n",
    "                                                   dataframe=race_past_x_result_df[model_params['FEATURETOOLS_PARAMS']['INDEX_COL']['RACE_PAST_X_RESULT'] + \n",
    "                                                                                                                 model_params['FEATURETOOLS_PARAMS']['FEATURE_COL']['RACE_PAST_X_RESULT']], \n",
    "                                                   index='race_horse_past_x_id')\n",
    "\n",
    "    r_master_table = ft.Relationship(es['race_master']['race_id'], es['race_table']['race_id'])\n",
    "    r_table_past_x = ft.Relationship(es['race_table']['race_horse_id'], es['race_past_x']['race_horse_id'])\n",
    "\n",
    "    es.add_relationships(relationships=[r_master_table])\n",
    "    es.add_relationships(relationships=[r_table_past_x])    \n",
    "    \n",
    "    feature_matrix_df, _ = ft.dfs(\n",
    "                                                     entityset=es,\n",
    "                                                     target_entity='race_table',\n",
    "                                                     agg_primitives=model_params['FEATURETOOLS_PARAMS']['PRIMITIVES']['aggregation'],\n",
    "                                                     trans_primitives =model_params['FEATURETOOLS_PARAMS']['PRIMITIVES']['transform'],\n",
    "                                                     max_depth=2\n",
    "                                                   )\n",
    "    feature_matrix_df  = feature_matrix_df.fillna(0)\n",
    "    table_index_df = decode_race_horse_id(feature_matrix_df)\n",
    "    feature_matrix_df = feature_matrix_df.reset_index(drop=True)\n",
    "    return feature_matrix_df, table_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix_df, table_index_df  = engeneer_features_by_featuretools(\n",
    "    model_params, race_master_df, race_table_result_df, race_past_x_result_df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(table_index_df.shape)\n",
    "print(feature_matrix_df.shape)\n",
    "feature_matrix_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection by 'boruta'\n",
    "- 参考URL: https://dev.classmethod.jp/machine-learning/yoshim-featuretools-boruta-optuna/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_data(feature_df, y_df, idx_df, model_params):\n",
    "    dataset = pd.concat([feature_df, y_df[model_params['TRAIN_TEST_SPLIT']['TARGET_COL']]], axis='columns')\n",
    "    dataset = pd.concat([idx_df, dataset], axis='columns')\n",
    "    \n",
    "    index_cols = model_params['TRAIN_TEST_SPLIT']['INDEX_COL']\n",
    "    feature_cols = [col for col in list(dataset.columns) if col not in model_params['TRAIN_TEST_SPLIT']['EXCLUDE_COL']]\n",
    "    target_col = model_params['TRAIN_TEST_SPLIT']['TARGET_COL']\n",
    "    criteria_to_split_dict = model_params['TRAIN_TEST_SPLIT']['CRITERIA_TO_SPLIT_DATA']\n",
    "    \n",
    "    Idx_train = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] < criteria_to_split_dict[list(criteria_to_split_dict)[0]]) |\n",
    "        (dataset[list(criteria_to_split_dict)[1]] < criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][index_cols]\n",
    "    Idx_train = Idx_train.loc[:,~Idx_train.columns.duplicated()]\n",
    "\n",
    "    X_train = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] < criteria_to_split_dict[list(criteria_to_split_dict)[0]]) |\n",
    "        (dataset[list(criteria_to_split_dict)[1]] < criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][feature_cols]\n",
    "\n",
    "    y_train = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] < criteria_to_split_dict[list(criteria_to_split_dict)[0]]) |\n",
    "        (dataset[list(criteria_to_split_dict)[1]] < criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][target_col]\n",
    "\n",
    "    Idx_test = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] >= criteria_to_split_dict[list(criteria_to_split_dict)[0]]) &\n",
    "        (dataset[list(criteria_to_split_dict)[1]] >= criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][index_cols]\n",
    "    Idx_test = Idx_test.loc[:,~Idx_test.columns.duplicated()]\n",
    "\n",
    "    X_test = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] >= criteria_to_split_dict[list(criteria_to_split_dict)[0]]) &\n",
    "        (dataset[list(criteria_to_split_dict)[1]] >= criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][feature_cols]\n",
    "\n",
    "    y_test = dataset[\n",
    "        (dataset[list(criteria_to_split_dict)[0]] >= criteria_to_split_dict[list(criteria_to_split_dict)[0]]) &\n",
    "        (dataset[list(criteria_to_split_dict)[1]] >= criteria_to_split_dict[list(criteria_to_split_dict)[1]])\n",
    "    ][target_col]\n",
    "    \n",
    "    return Idx_train, X_train, y_train, Idx_test, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Idx_train, X_train, y_train, Idx_test, X_test, y_test = make_train_test_data(\n",
    "    feature_matrix_df, race_table_result_df, table_index_df, model_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Idx_train.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(Idx_test.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boruta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from boruta import BorutaPy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features_by_boruta(X_train, y_train):\n",
    "    model = RandomForestRegressor(\n",
    "        n_estimators=50, \n",
    "        max_depth = 10, \n",
    "        max_features = 'sqrt', \n",
    "        n_jobs=-1, \n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    features_selector = BorutaPy(\n",
    "        model, \n",
    "        n_estimators='auto',\n",
    "         verbose=2,\n",
    "         alpha=0.5, # 有意水準\n",
    "         max_iter=30, # 試行回数\n",
    "         random_state=1\n",
    "    )\n",
    "    \n",
    "    features_selector.fit(X_train.values, y_train.values)\n",
    "    X_train_selected = X_train.iloc[:,features_selector.support_]\n",
    "    X_test_selected = X_test.iloc[:,features_selector.support_]\n",
    "    feature_selected_cols = list(X_train_selected.columns())\n",
    "    \n",
    "    return feature_selected_cols, X_train_selected, X_test_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_selected_cols, X_train_selected, X_test_selected = select_features_by_boruta(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning by 'h2o'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "h2o.init(ip=\"127.0.0.1\", max_mem_size_GB = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hdf = h2o.H2OFrame(pd.concat([X_train, y_train], axis=1))\n",
    "\n",
    "aml = H2OAutoML(max_models=2, seed=1, max_runtime_secs=28800)\n",
    "aml.train(\n",
    "    x = feature_cols, \n",
    "    y = target_col, \n",
    "    training_frame = hdf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lb = aml.leaderboard\n",
    "lb.head(rows=lb.nrows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aml.leader.varimp(use_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = aml.predict(h2o.H2OFrame(X_test)).as_data_frame()['predict']\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test_pred, y_test)))\n",
    "print('R2: ', r2_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### とりあえずRFで結果を出力する機構を作成する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    max_depth = 10, \n",
    "    max_features = 'sqrt', \n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame(rf_reg.feature_importances_, columns=[\"importance\"], index=feature_cols)\n",
    "feature_importance.sort_values(\"importance\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_test_pred = rf_reg.predict(X_test)\n",
    "print('RMSE: ', np.sqrt(mean_squared_error(y_test_pred, y_test)))\n",
    "print('R2: ', r2_score(y_test_pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ここまでがRFによるもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predited_score_df = pd.concat(\n",
    "    [Idx_test.reset_index(drop=True), pd.DataFrame(np.round(y_test_pred, 3), columns=['predicted_score'])], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predited_score_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predited_score_list = predited_score_df.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bulk_insert(insert_list, target_table_name, insert_col_names):\n",
    "    try:\n",
    "        bi = BulkInsert(con)\n",
    "        bi.execute(insert_data=insert_list, target_table=target_table_name, col_names=insert_col_names)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_bulk_insert(predited_score_list, 'race_predicted_score', parameters['TABLE_COL_NAMES']['race_predicted_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiling to check finally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import pandas_profiling as pdp\n",
    "# profile = pdp.ProfileReport(training_race_df)\n",
    "# profile.to_file(output_file=\"Model/profile_report.html\")\n",
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
