{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': 'daigo1123',\n",
    "    'database': 'dev_netkeiba',\n",
    "    'port': 3306,\n",
    "    'charset': 'utf8'\n",
    "}\n",
    "con = pymysql.connect(**db_params)\n",
    "\n",
    "parameters = {\n",
    "\n",
    "    # parameters about scraping\n",
    "    'URL_ABOUT_NETKEIBA': {\n",
    "        'RACE_TABLE': 'https://race.netkeiba.com/?pid=race_old&id=c',\n",
    "        'RACE_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=result',\n",
    "        'RACE_PAST5_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=shutuba'\n",
    "    },\n",
    "\n",
    "    # parameters about model training\n",
    "\n",
    "    # col names in database tables\n",
    "    'TABLE_COL_NAMES': {\n",
    "        'race_master': [\n",
    "            'race_id',\n",
    "            'race_title',\n",
    "            'race_course',\n",
    "            'race_weather',\n",
    "            'race_condition',\n",
    "            'race_year',\n",
    "            'race_month',\n",
    "            'race_date',\n",
    "            'race_dow',\n",
    "            'starting_time',\n",
    "            'race_info_1',\n",
    "            'race_info_2',\n",
    "            'race_info_3'\n",
    "        ],\n",
    "        'race_table_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'horse_name',\n",
    "            'horse_age',\n",
    "            'horse_sex',\n",
    "            'weight_penalty',\n",
    "            'jockey_name',\n",
    "            'href_to_jockey',\n",
    "            'owner_name',\n",
    "            'href_to_owner',\n",
    "            'horse_weight',\n",
    "            'horse_weight_increment',\n",
    "            'win_odds',\n",
    "            'popularity_order'\n",
    "        ],\n",
    "        'race_result_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'arrival_time',\n",
    "            'arrival_diff',\n",
    "            'arrrival_order'\n",
    "        ],\n",
    "        'race_refund_info': [\n",
    "            'race_id',\n",
    "            'refund_type',\n",
    "            'groupby_index',\n",
    "            'bracket_num',\n",
    "            'refund_yen',\n",
    "            'popularity_order'\n",
    "        ],\n",
    "        'race_past_5_result_info':[\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'past_x',\n",
    "            'arrival_order'\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # col names in dataframe\n",
    "    'DATAFRAME_COL_NAMES': {\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# def _execute_query(query):\n",
    "#     try:\n",
    "#         cursor = con.cursor()\n",
    "#         cursor.execute(query)\n",
    "#         cursor.close()\n",
    "#         con.commit()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "\n",
    "# def _truncate_target_rows(race_id):\n",
    "#     queries = [\n",
    "#         'TRUNCATE TABLE race_master WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id),\n",
    "#         'TRUNCATE TABLE race_table_info WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id)\n",
    "#     ]\n",
    "#     for query in queries:\n",
    "#         print(query)\n",
    "#         _execute_query(query)\n",
    "\n",
    "def _bulk_insert(insert_list, target_table_name, insert_col_names):\n",
    "    try:\n",
    "        bi = BulkInsert(con)\n",
    "        bi.execute(insert_data=insert_list, target_table=target_table_name, col_names=insert_col_names)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race prior table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_str(num):\n",
    "    num_str = str(num) if num >= 10 else '0' + str(num)\n",
    "    return num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race):\n",
    "#     race_id = str(event_year) + _get_num_str(event_place) + _get_num_str(event_month) + _get_num_str(event_time) + _get_num_str(event_race)\n",
    "#     target_url = parameters['URL_ABOUT_NETKEIBA']['RACE_TABLE'] + race_id\n",
    "    \n",
    "#     return race_id, target_url\n",
    "\n",
    "def _make_race_ids_list():\n",
    "    query = 'SELECT * FROM race_calender_master;'\n",
    "    return _fetchall_and_make_list_by(query)\n",
    "\n",
    "def _make_race_id_and_target_url(race_calender):\n",
    "    race_id = ''.join(map(lambda x: _get_num_str(x), race_calender))\n",
    "    target_url = parameters['URL_ABOUT_NETKEIBA']['RACE_TABLE'] + race_id\n",
    "    return race_id, target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _is_the_race_id_existing_in_master(race_id):\n",
    "    query_existing = \"\"\"\n",
    "        SELECT race_id FROM race_master WHERE race_id = '{RACE_ID}';\n",
    "    \"\"\".format(RACE_ID=race_id)\n",
    "    race_id_list_in_master_existing = _fetchall_and_make_list_by(query_existing)\n",
    "    query_not_existing = \"\"\"\n",
    "        SELECT race_id FROM race_master_not_existing WHERE race_id = '{RACE_ID}';\n",
    "    \"\"\".format(RACE_ID=race_id)\n",
    "    race_id_list_in_master_not_existing = _fetchall_and_make_list_by(query_not_existing)\n",
    "    race_id_list_in_master = race_id_list_in_master_existing + race_id_list_in_master_not_existing\n",
    "\n",
    "    if len(race_id_list_in_master) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_common_info(soup, race_id):\n",
    "    race_title = soup.find('div', class_='data_intro').find('h1').text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_coure = soup.find('div', class_='data_intro').find_all('p')[0].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_weather = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[0]\n",
    "    race_weather = re.search('天気：(.*)', race_weather).group(1)\n",
    "    \n",
    "    race_condition = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[1]\n",
    "    race_condition = re.search('馬場：(.*)', race_condition).group(1)\n",
    "    \n",
    "    starting_time = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[2]\n",
    "    starting_time = re.search('発走：(.*)', starting_time).group(1)\n",
    "    \n",
    "    race_date_info = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[0].text\n",
    "    race_year = re.split('/|\\(|\\)', race_date_info)[0]\n",
    "    race_month = re.split('/|\\(|\\)', race_date_info)[1]\n",
    "    race_date = re.split('/|\\(|\\)', race_date_info)[2]\n",
    "    race_dow = re.split('/|\\(|\\)', race_date_info)[3]\n",
    "    \n",
    "    race_info_1 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[1].text.replace(u'\\xa0',u' ')\n",
    "    race_info_2 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[2].text.replace(u'\\xa0',u' ')\n",
    "    race_info_3 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[3].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    return [race_id, race_title, race_coure, race_weather, race_condition, race_year, race_month, race_date, race_dow, starting_time, race_info_1, race_info_2, race_info_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_table(soup, race_id):\n",
    "    this_race_table_info = []\n",
    "    \n",
    "    table_length = len(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')) \n",
    "    for row in range(3, table_length):\n",
    "        bracket_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[0].text)\n",
    "        horse_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[1].text)\n",
    "        horse_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[3].find('a').text\n",
    "        sex_and_age = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[4].text\n",
    "        horse_age = int(re.sub(\"\\\\D\", \"\", sex_and_age))\n",
    "        horse_sex = re.match('[0-9a-zA-Zあ-んア-ン一-鿐]', sex_and_age).group()\n",
    "        weight_penalty = float(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[5].text)\n",
    "        jockey_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].text\n",
    "        href_to_jockey = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].find('a').attrs['href']\n",
    "        owner_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        href_to_owner = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].find('a').attrs['href']\n",
    "        horse_weight_info = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        if horse_weight_info != '':\n",
    "            horse_weight = int(re.split('\\(|\\)', horse_weight_info)[0])\n",
    "            horse_weight_increment = re.split('\\(|\\)', horse_weight_info)[1]\n",
    "        else:\n",
    "            horse_weight = ''\n",
    "            horse_weight_increment = ''\n",
    "\n",
    "        win_odds = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[9].text\n",
    "        popularity_order = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[10].text\n",
    "        \n",
    "        this_race_table_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            horse_name,\n",
    "            horse_age,\n",
    "            horse_sex,\n",
    "            weight_penalty,\n",
    "            jockey_name,\n",
    "            href_to_jockey,\n",
    "            owner_name,\n",
    "            href_to_owner,\n",
    "            horse_weight,\n",
    "            horse_weight_increment,\n",
    "            win_odds,\n",
    "            popularity_order\n",
    "        ])\n",
    "        \n",
    "    return this_race_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_insert_race_master_and_table_info():\n",
    "    race_calender_master_list = _make_race_ids_list()\n",
    "    for race_calender in race_calender_master_list:\n",
    "        race_id, target_url = _make_race_id_and_target_url(race_calender)\n",
    "\n",
    "#     for event_year in range(2019, 2020):\n",
    "#         for event_place in range(1,2):\n",
    "#             for event_month in range(1, 2):\n",
    "#                 for event_time in range(1, 2):\n",
    "#                     for event_race in range(1, 2):\n",
    "\n",
    "        race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)                    \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_old nk_tb_common'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            _bulk_insert([race_id], 'race_master_not_existing', parameters['TABLE_COL_NAMES']['race_master_not_existing'])\n",
    "            continue\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        try:\n",
    "            race_master_list = _extract_common_info(soup, race_id)\n",
    "            race_table_info_list = _extract_race_table(soup, race_id)\n",
    "            if ' ' in race_master_list:\n",
    "                    continue\n",
    "        except AttributeError:\n",
    "            print('\\t This URL has no master info')\n",
    "        _bulk_insert(race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])\n",
    "        _bulk_insert(race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_master_list, race_table_info_list = get_and_insert_race_master_and_table_info()\n",
    "# get_and_insert_race_master_and_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_calender_master_list = _make_race_ids_list()\n",
    "race_calender = race_calender_master_list[0]\n",
    "print(race_calender)\n",
    "race_calender = (2019, 3, 3, 2, 1)\n",
    "race_id, target_url = _make_race_id_and_target_url(race_calender)\n",
    "\n",
    "print(race_id)\n",
    "print('Target URL to requests: ', target_url)\n",
    "\n",
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_master_list = _extract_common_info(soup, race_id)\n",
    "race_master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_table_info_list = _extract_race_table(soup, race_id)\n",
    "race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query, con):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_target_url_about_race_result(race_id):\n",
    "        return parameters['URL_ABOUT_NETKEIBA']['RACE_RESULT'].format(RACE_ID=race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_ids_in_master_not_exist_in_race_result():\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id NOT IN (SELECT DISTINCT race_id FROM race_result_info);\n",
    "    \"\"\"\n",
    "    result = _fetchall_and_make_list_by(query, con)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_result_info(soup, race_id):\n",
    "    this_race_result_info = []\n",
    "    table_length = len(soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr'))\n",
    "    \n",
    "    for row in range(1, table_length):\n",
    "        arrrival_order  = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[0].text\n",
    "        bracket_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[1].text\n",
    "        horse_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[2].text\n",
    "        arrival_time = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        arrival_diff = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        \n",
    "        this_race_result_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            arrival_time,\n",
    "            arrival_diff,\n",
    "            arrrival_order\n",
    "        ])\n",
    "\n",
    "    return this_race_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_refund_info(soup, race_id):\n",
    "    empty_refund_list = []\n",
    "    refund_table_list = soup.find('dd', class_='fc').find_all('tr')\n",
    "    for i in range(len(refund_table_list)):\n",
    "        refund_table = refund_table_list[i]\n",
    "        refund_type = refund_table.find('th').text\n",
    "\n",
    "        if refund_type == '単勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '単勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '複勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text[:2]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 2,  \n",
    "                 int(refund_table.find_all('td')[0].text[2:4]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            try:\n",
    "                empty_refund_list.append(\n",
    "                    [race_id, '複勝', 3, \n",
    "                     int(refund_table.find_all('td')[0].text[4:6]),\n",
    "                     int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                     int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "                )\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        elif refund_type == '枠連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '馬連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == 'ワイド':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[:2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[5:7]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[7:9]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[12:14]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1])],            \n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[14:16]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[19:22]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == '馬単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0])]             \n",
    "            )\n",
    "            \n",
    "        elif refund_type == '三連複':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))] \n",
    "            )       \n",
    "            \n",
    "        elif refund_type == '三連単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )                \n",
    "\n",
    "    return empty_refund_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_result_info():\n",
    "    existing_race_ids_in_master = _extract_race_ids_in_master()\n",
    "    \n",
    "    for id_idx in range(len(existing_race_ids_in_master)):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = _make_target_url_about_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        race_result_info_list = _extract_race_result_info(soup, race_id)\n",
    "        race_refund_info_list = _extract_race_refund_info(soup, race_id)\n",
    "        \n",
    "        _bulk_insert(race_result_info_list, 'race_result_info', parameters['TABLE_COL_NAMES']['race_result_info'])\n",
    "        _bulk_insert(race_refund_info_list, 'race_refund_info', parameters['TABLE_COL_NAMES']['race_refund_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get_race_result_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_id = '201506050811'\n",
    "# target_url = 'https://race.netkeiba.com/?pid=race&id=p201506050811&mode=result'\n",
    "# html = requests.get(target_url)\n",
    "# html.encoding = 'EUC-JP'\n",
    "# soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# refund_table_list = soup.find('dd', class_='fc').find_all('tr')\n",
    "# refund_table_list[1].find_all('td')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _extract_race_refund_info(soup, race_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about past 5 race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_ids_in_master_not_exist_in_race_past_5_result():\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id NOT IN (SELECT DISTINCT race_id FROM race_past_5_result_info);\n",
    "    \"\"\"\n",
    "    result = _fetchall_and_make_list_by(query, con)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_target_url_about_past_5_race_result(race_id):\n",
    "    return parameters['URL_ABOUT_NETKEIBA']['RACE_PAST5_RESULT'].format(RACE_ID=race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_past_5_race_result(soup, race_id):\n",
    "    this_race_past5_result_info = []\n",
    "    table_element = soup.find('table', class_='race_table_01 nk_tb_common shutuba_table').find_all('tr')\n",
    "    table_length = len(table_element)\n",
    "\n",
    "    for row in range(1, table_length):\n",
    "        bracket_num = table_element[row].find_all('td')[0].text\n",
    "        horse_num = table_element[row].find_all('td')[1].text\n",
    "\n",
    "        post_x = 0\n",
    "        for col in range(1, 15):\n",
    "            try:\n",
    "                race_name_element = table_element[row].find_all('td')[col].find('span', class_='race_name')\n",
    "                past_x_race_title = race_name_element.text\n",
    "                past_x_race_id = int(re.sub('\\\\D', '', race_name_element.find('a').attrs['href']))\n",
    "                order = table_element[row].find_all('td')[col].find('span', class_='order').text\n",
    "                post_x += 1\n",
    "                this_race_past5_result_info.append([race_id, bracket_num, horse_num, post_x, past_x_race_title,  past_x_race_id, order])\n",
    "            except (IndexError, AttributeError):\n",
    "                pass\n",
    "\n",
    "    return this_race_past5_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_5_race_result_info():\n",
    "    existing_race_ids_in_master = _extract_race_ids_in_master_not_exist_in_race_past_5_result()\n",
    "    \n",
    "    for id_idx in range(len(existing_race_ids_in_master)):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = _make_target_url_about_past_5_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common shutuba_table'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        race_past5_result_info_list = _extract_past_5_race_result(soup, race_id)        \n",
    "        _bulk_insert(race_past5_result_info_list, 'race_past_5_result_info', \n",
    "                     parameters['TABLE_COL_NAMES']['race_past_5_result_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_id = '201910020609'\n",
    "# target_url = _make_target_url_about_past_5_race_result(race_id)\n",
    "# print(target_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# html = requests.get(target_url)\n",
    "# html.encoding = 'EUC-JP'\n",
    "# soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _extract_past_5_race_result(soup, race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
