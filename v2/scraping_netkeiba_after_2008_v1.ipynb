{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': 'daigo1123',\n",
    "    'database': 'dev_netkeiba',\n",
    "    'port': 3306,\n",
    "    'charset': 'utf8'\n",
    "}\n",
    "con = pymysql.connect(**db_params)\n",
    "\n",
    "parameters = {\n",
    "\n",
    "    # parameters about scraping\n",
    "    'URL_ABOUT_NETKEIBA': {\n",
    "        'RACE_TABLE': 'https://race.netkeiba.com/?pid=race_old&id=c',\n",
    "        'RACE_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=result'\n",
    "    },\n",
    "\n",
    "    # parameters about model training\n",
    "\n",
    "    # col names in database tables\n",
    "    'TABLE_COL_NAMES': {\n",
    "        'race_master': [\n",
    "            'race_id',\n",
    "            'race_title',\n",
    "            'race_coure',\n",
    "            'race_weather',\n",
    "            'race_condition',\n",
    "            'race_year',\n",
    "            'race_month',\n",
    "            'race_date',\n",
    "            'race_dow',\n",
    "            'starting_time',\n",
    "            'race_info_1',\n",
    "            'race_info_2',\n",
    "            'race_info_3'\n",
    "        ],\n",
    "        'race_table_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'horse_name',\n",
    "            'horse_age',\n",
    "            'horse_sex',\n",
    "            'weight_penalty',\n",
    "            'jockey_name',\n",
    "            'href_to_jockey',\n",
    "            'owner_name',\n",
    "            'href_to_owner',\n",
    "            'horse_weight',\n",
    "            'horse_weight_increment',\n",
    "            'win_odds',\n",
    "            'popularity_order'\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # col names in dataframe\n",
    "    'DATAFRAME_COL_NAMES': {\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race prior table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_str(num):\n",
    "    num_str = str(num) if num >= 10 else '0' + str(num)\n",
    "    return num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race):\n",
    "    race_id = str(event_year) + get_num_str(event_place) + get_num_str(event_month) + get_num_str(event_time) + get_num_str(event_race)\n",
    "    target_url = parameters['URL_ABOUT_NETKEIBA']['RACE_TABLE'] + race_id\n",
    "    \n",
    "    return race_id, target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_request_result_ng(html, soup):\n",
    "    if html.status_code == 200 and soup.find_all('table', attrs={'class', 'race_table_old nk_tb_common'}) != []:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_common_info(soup, race_id):\n",
    "    race_title = soup.find('div', class_='data_intro').find('h1').text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_coure = soup.find('div', class_='data_intro').find_all('p')[0].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_weather = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[0]\n",
    "    race_weather = re.search('天気：(.*)', race_weather).group(1)\n",
    "    \n",
    "    race_condition = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[1]\n",
    "    race_condition = re.search('馬場：(.*)', race_condition).group(1)\n",
    "    \n",
    "    starting_time = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[2]\n",
    "    starting_time = re.search('発走：(.*)', starting_time).group(1)\n",
    "    \n",
    "    race_date_info = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[0].text\n",
    "    race_year = re.split('/|\\(|\\)', race_date_info)[0]\n",
    "    race_month = re.split('/|\\(|\\)', race_date_info)[1]\n",
    "    race_date = re.split('/|\\(|\\)', race_date_info)[2]\n",
    "    race_dow = re.split('/|\\(|\\)', race_date_info)[3]\n",
    "    \n",
    "    race_info_1 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[1].text.replace(u'\\xa0',u' ')\n",
    "    race_info_2 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[2].text.replace(u'\\xa0',u' ')\n",
    "    race_info_3 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[3].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    return race_id, race_title, race_coure, race_weather, race_condition, race_year, race_month, race_date, race_dow, starting_time, race_info_1, race_info_2, race_info_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_race_table(soup, race_id):\n",
    "    this_race_table_info = []\n",
    "    \n",
    "    table_length = len(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')) \n",
    "    for row in range(3, table_length):\n",
    "        bracket_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[0].text)\n",
    "        horse_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[1].text)\n",
    "        horse_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[3].find('a').text\n",
    "        sex_and_age = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[4].text\n",
    "        horse_age = int(re.sub(\"\\\\D\", \"\", sex_and_age))\n",
    "        horse_sex = re.match('[0-9a-zA-Zあ-んア-ン一-鿐]', sex_and_age).group()\n",
    "        weight_penalty = float(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[5].text)\n",
    "        jockey_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].text\n",
    "        href_to_jockey = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].find('a').attrs['href']\n",
    "        owner_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        href_to_owner = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].find('a').attrs['href']\n",
    "        horse_weight_info = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        if horse_weight_info != '':\n",
    "            horse_weight = int(re.split('\\(|\\)', horse_weight_info)[0])\n",
    "            horse_weight_increment = re.split('\\(|\\)', horse_weight_info)[1]\n",
    "        else:\n",
    "            horse_weight = ''\n",
    "            horse_weight_increment = ''\n",
    "\n",
    "        win_odds = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[9].text\n",
    "        popularity_order = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[10].text\n",
    "        \n",
    "        this_race_table_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            horse_name,\n",
    "            horse_age,\n",
    "            horse_sex,\n",
    "            weight_penalty,\n",
    "            jockey_name,\n",
    "            href_to_jockey,\n",
    "            owner_name,\n",
    "            href_to_owner,\n",
    "            horse_weight,\n",
    "            horse_weight_increment,\n",
    "            win_odds,\n",
    "            popularity_order\n",
    "        ])\n",
    "        \n",
    "    return this_race_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _execute_query(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        cursor.close()\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def _truncate_target_rows(race_id):\n",
    "    queries = [\n",
    "        'TRUNCATE TABLE race_master WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id),\n",
    "        'TRUNCATE TABLE race_table_info WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id)\n",
    "    ]\n",
    "    for query in queries:\n",
    "        print(query)\n",
    "        _execute_query(query)\n",
    "\n",
    "def _bulk_insert(race_id, insert_list, target_table_name, insert_col_names):\n",
    "    try:\n",
    "        bi = BulkInsert(con)\n",
    "        bi.execute(insert_data=insert_list, target_table=target_table_name, col_names=insert_col_names)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        _truncate_target_rows(race_id)\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_insert_race_master_and_table_info():\n",
    "    for event_year in range(2019, 2020):\n",
    "        for event_place in range(1,2):\n",
    "            for event_month in range(1, 2):\n",
    "                for event_time in range(1, 2):\n",
    "                    for event_race in range(1, 2):\n",
    "                        race_master_list = []\n",
    "                        race_table_info_list = []\n",
    "                        race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)                    \n",
    "                        html = requests.get(target_url)\n",
    "                        html.encoding = 'EUC-JP'\n",
    "                        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "                        if is_request_result_ng(html, soup):\n",
    "                            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "                            break\n",
    "\n",
    "                        print('Target URL to requests: ', target_url)\n",
    "                        race_master_list.append(extract_common_info(soup, race_id))\n",
    "                        race_table_info_list = race_table_info_list + extract_race_table(soup, race_id)\n",
    "                        time.sleep(1)\n",
    "                    \n",
    "                    _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])\n",
    "                    _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        \n",
    "                \n",
    "    return race_master_list, race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_master_list, race_table_info_list = get_and_insert_race_master_and_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(pd.DataFrame(race_master_list).shape)\n",
    "print(pd.DataFrame(race_table_info_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(race_master_list).to_csv('race_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(race_table_info_list).to_csv('race_table_info_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201904020602\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race_old&id=c201904020602\n"
     ]
    }
   ],
   "source": [
    "event_year = 2019\n",
    "event_place = 4 \n",
    "event_month = 2\n",
    "event_time = 6\n",
    "event_race = 2\n",
    "\n",
    "race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)\n",
    "print(race_id)\n",
    "print('Target URL to requests: ', target_url)\n",
    "\n",
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_request_result_ng(html, soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_master_list = list(extract_common_info(soup, race_id))\n",
    "# race_master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_table_info_list = extract_race_table(soup, race_id)\n",
    "# race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query, con):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_existing_race_ids_in_master():\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id NOT IN (SELECT DISTINCT race_id FROM race_result_info);\n",
    "    \"\"\"\n",
    "    result = _fetchall_and_make_list_by(query, con)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('201901010101',)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existing_race_ids_in_master = extract_existing_race_ids_in_master()\n",
    "existing_race_ids_in_master[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://race.netkeiba.com/?pid=race&id=c201901010101&mode=result\n"
     ]
    }
   ],
   "source": [
    "id_idx = 0\n",
    "race_id = existing_race_ids_in_master[id_idx][0]\n",
    "target_url_about_result = make_target_url_about_race_result(race_id)\n",
    "print(target_url_about_result) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(target_url_about_result)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_length = len(soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr'))\n",
    "table_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_race_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrrival_order  = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[0].text\n",
    "arrrival_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bracket_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[1].text\n",
    "bracket_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "horse_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[2].text\n",
    "horse_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1:50.1'"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_time = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "arrival_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_diff = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "arrival_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大'"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrival_diff = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "arrival_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <th class=\"tan\">単勝</th>\n",
       " <td>01</td>\n",
       " <td class=\"txt_r\">140円</td>\n",
       " <td class=\"txt_r\">1人気</td>\n",
       " </tr>, <tr>\n",
       " <th align=\"center\" class=\"fuku\">複勝</th>\n",
       " <td>01<br/>03<br/>04</td>\n",
       " <td class=\"txt_r\">110円<br/>110円<br/>470円</td>\n",
       " <td class=\"txt_r\">1人気<br/>2人気<br/>7人気</td>\n",
       " </tr>, <tr>\n",
       " <th align=\"center\" class=\"waku\">枠連</th>\n",
       " <td>01 - 03</td>\n",
       " <td class=\"txt_r\">190円</td>\n",
       " <td class=\"txt_r\">1人気</td>\n",
       " </tr>, <tr>\n",
       " <th align=\"center\" class=\"uren\">馬連</th>\n",
       " <td>01 - 03</td>\n",
       " <td class=\"txt_r\">190円</td>\n",
       " <td class=\"txt_r\">1人気</td>\n",
       " </tr>, <tr>\n",
       " <th class=\"wide\">ワイド</th>\n",
       " <td>01 - 03<br/>01 - 04<br/>03 - 04</td>\n",
       " <td class=\"txt_r\">120円<br/>840円<br/>1,100円</td>\n",
       " <td class=\"txt_r\">1人気<br/>11人気<br/>13人気</td>\n",
       " </tr>, <tr>\n",
       " <th class=\"utan\">馬単</th>\n",
       " <td>01 → 03</td>\n",
       " <td class=\"txt_r\">290円</td>\n",
       " <td class=\"txt_r\">1人気</td>\n",
       " </tr>, <tr>\n",
       " <th class=\"sanfuku\">三連複</th>\n",
       " <td>01 - 03 - 04</td>\n",
       " <td class=\"txt_r\">1,610円</td>\n",
       " <td class=\"txt_r\">6人気</td>\n",
       " </tr>, <tr>\n",
       " <th class=\"santan\">三連単</th>\n",
       " <td>01 → 03 → 04</td>\n",
       " <td class=\"txt_r\">3,560円</td>\n",
       " <td class=\"txt_r\">10人気</td>\n",
       " </tr>]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('dd', class_='fc').find_all('tr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_result_info():\n",
    "    existing_race_ids_in_master = extract_existing_race_ids_in_master()\n",
    "    \n",
    "    race_result_info_list = []\n",
    "    rece_refund_info_list = []\n",
    "    \n",
    "    for id_idx in len(existing_race_ids_in_master):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = make_target_url_about_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        \n",
    "        race_result_list = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
