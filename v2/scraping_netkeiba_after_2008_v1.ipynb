{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': 'daigo1123',\n",
    "    'database': 'dev_netkeiba',\n",
    "    'port': 3306,\n",
    "    'charset': 'utf8'\n",
    "}\n",
    "con = pymysql.connect(**db_params)\n",
    "\n",
    "parameters = {\n",
    "\n",
    "    # parameters about scraping\n",
    "    'URL_ABOUT_NETKEIBA': {\n",
    "        'RACE_TABLE': 'https://race.netkeiba.com/?pid=race_old&id=c',\n",
    "        'RACE_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=result'\n",
    "    },\n",
    "\n",
    "    # parameters about model training\n",
    "\n",
    "    # col names in database tables\n",
    "    'TABLE_COL_NAMES': {\n",
    "        'race_master': [\n",
    "            'race_id',\n",
    "            'race_title',\n",
    "            'race_coure',\n",
    "            'race_weather',\n",
    "            'race_condition',\n",
    "            'race_year',\n",
    "            'race_month',\n",
    "            'race_date',\n",
    "            'race_dow',\n",
    "            'starting_time',\n",
    "            'race_info_1',\n",
    "            'race_info_2',\n",
    "            'race_info_3'\n",
    "        ],\n",
    "        'race_table_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'horse_name',\n",
    "            'horse_age',\n",
    "            'horse_sex',\n",
    "            'weight_penalty',\n",
    "            'jockey_name',\n",
    "            'href_to_jockey',\n",
    "            'owner_name',\n",
    "            'href_to_owner',\n",
    "            'horse_weight',\n",
    "            'horse_weight_increment',\n",
    "            'win_odds',\n",
    "            'popularity_order'\n",
    "        ],\n",
    "        'race_result_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'arrival_time',\n",
    "            'arrival_diff',\n",
    "            'arrrival_order'\n",
    "        ],\n",
    "        'race_refund_info': [\n",
    "            'race_id',\n",
    "            'refund_type',\n",
    "            'groupby_index',\n",
    "            'bracket_num',\n",
    "            'refund_yen',\n",
    "            'popularity_order'\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # col names in dataframe\n",
    "    'DATAFRAME_COL_NAMES': {\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race prior table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_str(num):\n",
    "    num_str = str(num) if num >= 10 else '0' + str(num)\n",
    "    return num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race):\n",
    "    race_id = str(event_year) + _get_num_str(event_place) + _get_num_str(event_month) + _get_num_str(event_time) + _get_num_str(event_race)\n",
    "    target_url = parameters['URL_ABOUT_NETKEIBA']['RACE_TABLE'] + race_id\n",
    "    \n",
    "    return race_id, target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_common_info(soup, race_id):\n",
    "    race_title = soup.find('div', class_='data_intro').find('h1').text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_coure = soup.find('div', class_='data_intro').find_all('p')[0].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_weather = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[0]\n",
    "    race_weather = re.search('天気：(.*)', race_weather).group(1)\n",
    "    \n",
    "    race_condition = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[1]\n",
    "    race_condition = re.search('馬場：(.*)', race_condition).group(1)\n",
    "    \n",
    "    starting_time = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[2]\n",
    "    starting_time = re.search('発走：(.*)', starting_time).group(1)\n",
    "    \n",
    "    race_date_info = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[0].text\n",
    "    race_year = re.split('/|\\(|\\)', race_date_info)[0]\n",
    "    race_month = re.split('/|\\(|\\)', race_date_info)[1]\n",
    "    race_date = re.split('/|\\(|\\)', race_date_info)[2]\n",
    "    race_dow = re.split('/|\\(|\\)', race_date_info)[3]\n",
    "    \n",
    "    race_info_1 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[1].text.replace(u'\\xa0',u' ')\n",
    "    race_info_2 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[2].text.replace(u'\\xa0',u' ')\n",
    "    race_info_3 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[3].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    return race_id, race_title, race_coure, race_weather, race_condition, race_year, race_month, race_date, race_dow, starting_time, race_info_1, race_info_2, race_info_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_table(soup, race_id):\n",
    "    this_race_table_info = []\n",
    "    \n",
    "    table_length = len(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')) \n",
    "    for row in range(3, table_length):\n",
    "        bracket_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[0].text)\n",
    "        horse_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[1].text)\n",
    "        horse_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[3].find('a').text\n",
    "        sex_and_age = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[4].text\n",
    "        horse_age = int(re.sub(\"\\\\D\", \"\", sex_and_age))\n",
    "        horse_sex = re.match('[0-9a-zA-Zあ-んア-ン一-鿐]', sex_and_age).group()\n",
    "        weight_penalty = float(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[5].text)\n",
    "        jockey_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].text\n",
    "        href_to_jockey = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].find('a').attrs['href']\n",
    "        owner_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        href_to_owner = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].find('a').attrs['href']\n",
    "        horse_weight_info = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        if horse_weight_info != '':\n",
    "            horse_weight = int(re.split('\\(|\\)', horse_weight_info)[0])\n",
    "            horse_weight_increment = re.split('\\(|\\)', horse_weight_info)[1]\n",
    "        else:\n",
    "            horse_weight = ''\n",
    "            horse_weight_increment = ''\n",
    "\n",
    "        win_odds = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[9].text\n",
    "        popularity_order = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[10].text\n",
    "        \n",
    "        this_race_table_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            horse_name,\n",
    "            horse_age,\n",
    "            horse_sex,\n",
    "            weight_penalty,\n",
    "            jockey_name,\n",
    "            href_to_jockey,\n",
    "            owner_name,\n",
    "            href_to_owner,\n",
    "            horse_weight,\n",
    "            horse_weight_increment,\n",
    "            win_odds,\n",
    "            popularity_order\n",
    "        ])\n",
    "        \n",
    "    return this_race_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _execute_query(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        cursor.close()\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def _truncate_target_rows(race_id):\n",
    "    queries = [\n",
    "        'TRUNCATE TABLE race_master WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id),\n",
    "        'TRUNCATE TABLE race_table_info WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id)\n",
    "    ]\n",
    "    for query in queries:\n",
    "        print(query)\n",
    "        _execute_query(query)\n",
    "\n",
    "def _bulk_insert(race_id, insert_list, target_table_name, insert_col_names):\n",
    "    try:\n",
    "        bi = BulkInsert(con)\n",
    "        bi.execute(insert_data=insert_list, target_table=target_table_name, col_names=insert_col_names)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        _truncate_target_rows(race_id)\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_insert_race_master_and_table_info():\n",
    "    for event_year in range(2019, 2020):\n",
    "        for event_place in range(1,2):\n",
    "            for event_month in range(1, 2):\n",
    "                for event_time in range(1, 2):\n",
    "                    for event_race in range(1, 2):\n",
    "                        race_master_list = []\n",
    "                        race_table_info_list = []\n",
    "                        race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)                    \n",
    "                        html = requests.get(target_url)\n",
    "                        html.encoding = 'EUC-JP'\n",
    "                        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "                        if not soup.find_all('table', attrs={'class', 'race_table_old nk_tb_common'}):\n",
    "                            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "                            break\n",
    "\n",
    "                        print('Target URL to requests: ', target_url)\n",
    "                        race_master_list.append(_extract_common_info(soup, race_id))\n",
    "                        race_table_info_list = race_table_info_list + _extract_race_table(soup, race_id)\n",
    "                        _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])\n",
    "                        _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        \n",
    "                        \n",
    "                        time.sleep(1)\n",
    "                \n",
    "#     return race_master_list, race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_master_list, race_table_info_list = get_and_insert_race_master_and_table_info()\n",
    "get_and_insert_race_master_and_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(race_master_list).shape)\n",
    "# print(pd.DataFrame(race_table_info_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(race_master_list).to_csv('race_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(race_table_info_list).to_csv('race_table_info_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_year = 2019\n",
    "event_place = 4 \n",
    "event_month = 2\n",
    "event_time = 6\n",
    "event_race = 2\n",
    "\n",
    "race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)\n",
    "print(race_id)\n",
    "print('Target URL to requests: ', target_url)\n",
    "\n",
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "race_master_list = _extract_common_info(soup, race_id)\n",
    "# race_master_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_table_info_list = _extract_race_table(soup, race_id)\n",
    "# race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query, con):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_target_url_about_race_result(race_id):\n",
    "        return parameters['URL_ABOUT_NETKEIBA']['RACE_RESULT'].format(RACE_ID=race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_ids_in_master():\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id NOT IN (SELECT DISTINCT race_id FROM race_result_info);\n",
    "    \"\"\"\n",
    "    result = _fetchall_and_make_list_by(query, con)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_result_info(soup, race_id):\n",
    "    this_race_result_info = []\n",
    "    table_length = len(soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr'))\n",
    "    \n",
    "    for row in range(1, table_length):\n",
    "        arrrival_order  = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[0].text\n",
    "        bracket_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[1].text\n",
    "        horse_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[2].text\n",
    "        arrival_time = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        arrival_diff = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        \n",
    "        this_race_result_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            arrival_time,\n",
    "            arrival_diff,\n",
    "            arrrival_order\n",
    "        ])\n",
    "\n",
    "    return this_race_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_refund_info(soup, race_id):\n",
    "    empty_refund_list = []\n",
    "    refund_table_list = soup.find('dd', class_='fc').find_all('tr')\n",
    "    for i in range(len(refund_table_list)):\n",
    "        refund_table = refund_table_list[i]\n",
    "        refund_type = refund_table.find('th').text\n",
    "\n",
    "        if refund_type == '単勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '単勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '複勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text[:2]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 2,  \n",
    "                 int(refund_table.find_all('td')[0].text[2:4]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            try:\n",
    "                empty_refund_list.append(\n",
    "                    [race_id, '複勝', 3, \n",
    "                     int(refund_table.find_all('td')[0].text[4:6]),\n",
    "                     int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                     int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "                )\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        elif refund_type == '枠連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '馬連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == 'ワイド':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[:2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[5:7]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[7:9]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[12:14]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1])],            \n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[14:16]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[19:22]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == '馬単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0])]             \n",
    "            )\n",
    "            \n",
    "        elif refund_type == '三連複':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))] \n",
    "            )       \n",
    "            \n",
    "        elif refund_type == '三連単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )                \n",
    "\n",
    "    return empty_refund_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_result_info():\n",
    "    existing_race_ids_in_master = _extract_race_ids_in_master()\n",
    "    \n",
    "    for id_idx in range(len(existing_race_ids_in_master)):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = _make_target_url_about_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        race_result_info_list = _extract_race_result_info(soup, race_id)\n",
    "        rece_refund_info_list = _extract_race_refund_info(soup, race_id)\n",
    "        \n",
    "        _bulk_insert(race_id, race_result_info_list, 'race_result_info', parameters['TABLE_COL_NAMES']['race_result_info'])\n",
    "        _bulk_insert(race_id, rece_refund_info_list, 'race_refund_info', parameters['TABLE_COL_NAMES']['race_refund_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010304&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010305&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010306&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010307&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010308&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010309&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010310&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010311&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010312&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010401&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010402&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010403&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010404&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010405&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010406&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010407&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010408&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010409&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010410&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010411&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010412&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010501&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010502&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010503&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010504&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010505&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010506&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010507&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010508&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010509&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010510&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010511&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010512&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010601&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010602&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010603&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010604&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010605&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010606&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010607&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010608&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010609&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010610&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010611&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901010612&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020101&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020102&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020103&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020104&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020105&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020106&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020107&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020108&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020109&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020110&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020111&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020112&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020201&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020202&mode=result\n",
      "Target URL to requests:  https://race.netkeiba.com/?pid=race&id=c201901020203&mode=result\n"
     ]
    }
   ],
   "source": [
    "get_race_result_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = _make_target_url_about_race_result(race_id)\n",
    "target_url = ' https://race.netkeiba.com/?pid=race&id=c201901010304&mode=result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '1,128'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b3d5100b90bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mrace_result_info_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_race_result_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrece_refund_info_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_race_refund_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrace_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-02687da37c43>\u001b[0m in \u001b[0;36m_extract_race_refund_info\u001b[0;34m(soup, race_id)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefund_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'→'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrefund_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'円'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                 int(refund_table.find_all('td')[2].text.split('人気')[0])]\n\u001b[0m\u001b[1;32m    145\u001b[0m             )\n\u001b[1;32m    146\u001b[0m             empty_refund_list.append(\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '1,128'"
     ]
    }
   ],
   "source": [
    "race_result_info_list = _extract_race_result_info(soup, race_id)\n",
    "rece_refund_info_list = _extract_race_refund_info(soup, race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['201901010201', '4', '5', '1:46.6', '', '1'],\n",
       " ['201901010201', '5', '7', '1:47.1', '3', '2'],\n",
       " ['201901010201', '6', '9', '1:47.3', '1', '3'],\n",
       " ['201901010201', '7', '12', '1:47.3', 'アタマ', '4'],\n",
       " ['201901010201', '8', '13', '1:47.3', 'ハナ', '5'],\n",
       " ['201901010201', '3', '3', '1:47.5', '1', '6'],\n",
       " ['201901010201', '2', '2', '1:47.6', '1/2', '7'],\n",
       " ['201901010201', '5', '8', '1:47.7', '3/4', '8'],\n",
       " ['201901010201', '7', '11', '1:48.0', '1.3/4', '9'],\n",
       " ['201901010201', '8', '14', '1:48.2', '1.1/2', '10'],\n",
       " ['201901010201', '3', '4', '1:48.4', '1.1/4', '11'],\n",
       " ['201901010201', '6', '10', '1:48.7', '1.3/4', '12'],\n",
       " ['201901010201', '1', '1', '1:48.8', '1/2', '13'],\n",
       " ['201901010201', '4', '6', '1:49.0', '1', '14']]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "race_result_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['201901010201', '単勝', 1, 10, 1580, 5],\n",
       " ['201901010201', '複勝', 1, 10, 460, 5],\n",
       " ['201901010201', '複勝', 2, 9, 280, 4],\n",
       " ['201901010201', '複勝', 3, 6, 550, 7],\n",
       " ['201901010201', '枠連', 1, 7, 8100, 21],\n",
       " ['201901010201', '枠連', 1, 7, 8100, 21],\n",
       " ['201901010201', '馬連', 1, 9, 8670, 27],\n",
       " ['201901010201', '馬連', 1, 10, 8670, 27],\n",
       " ['201901010201', 'ワイド', 1, 9, 2210, 26],\n",
       " ['201901010201', 'ワイド', 1, 10, 2210, 26],\n",
       " ['201901010201', 'ワイド', 2, 6, 4230, 38],\n",
       " ['201901010201', 'ワイド', 2, 10, 4230, 38],\n",
       " ['201901010201', 'ワイド', 3, 6, 2020, 21],\n",
       " ['201901010201', 'ワイド', 3, 9, 2020, 21],\n",
       " ['201901010201', '馬単', 1, 10, 19000, 53],\n",
       " ['201901010201', '馬単', 1, 9, 19000, 53],\n",
       " ['201901010201', '三連複', 1, 6, 46370, 106],\n",
       " ['201901010201', '三連複', 1, 9, 46370, 106],\n",
       " ['201901010201', '三連複', 1, 10, 46370, 106],\n",
       " ['201901010201', '三連単', 1, 10, 278750, 572],\n",
       " ['201901010201', '三連単', 1, 9, 278750, 572],\n",
       " ['201901010201', '三連単', 1, 6, 278750, 572]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rece_refund_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
