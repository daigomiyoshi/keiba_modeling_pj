{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from bs4 import BeautifulSoup\n",
    "import pymysql\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "\n",
    "from Utils.bulk_insert import BulkInsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': '127.0.0.1',\n",
    "    'user': 'root',\n",
    "    'password': 'daigo1123',\n",
    "    'database': 'dev_netkeiba',\n",
    "    'port': 3306,\n",
    "    'charset': 'utf8'\n",
    "}\n",
    "con = pymysql.connect(**db_params)\n",
    "\n",
    "parameters = {\n",
    "\n",
    "    # parameters about scraping\n",
    "    'URL_ABOUT_NETKEIBA': {\n",
    "        'RACE_TABLE': 'https://race.netkeiba.com/?pid=race_old&id=c',\n",
    "        'RACE_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=result',\n",
    "        'RACE_PAST5_RESULT': 'https://race.netkeiba.com/?pid=race&id=c{RACE_ID}&mode=shutuba'\n",
    "    },\n",
    "\n",
    "    # parameters about model training\n",
    "\n",
    "    # col names in database tables\n",
    "    'TABLE_COL_NAMES': {\n",
    "        'race_master': [\n",
    "            'race_id',\n",
    "            'race_title',\n",
    "            'race_coure',\n",
    "            'race_weather',\n",
    "            'race_condition',\n",
    "            'race_year',\n",
    "            'race_month',\n",
    "            'race_date',\n",
    "            'race_dow',\n",
    "            'starting_time',\n",
    "            'race_info_1',\n",
    "            'race_info_2',\n",
    "            'race_info_3'\n",
    "        ],\n",
    "        'race_table_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'horse_name',\n",
    "            'horse_age',\n",
    "            'horse_sex',\n",
    "            'weight_penalty',\n",
    "            'jockey_name',\n",
    "            'href_to_jockey',\n",
    "            'owner_name',\n",
    "            'href_to_owner',\n",
    "            'horse_weight',\n",
    "            'horse_weight_increment',\n",
    "            'win_odds',\n",
    "            'popularity_order'\n",
    "        ],\n",
    "        'race_result_info': [\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'arrival_time',\n",
    "            'arrival_diff',\n",
    "            'arrrival_order'\n",
    "        ],\n",
    "        'race_refund_info': [\n",
    "            'race_id',\n",
    "            'refund_type',\n",
    "            'groupby_index',\n",
    "            'bracket_num',\n",
    "            'refund_yen',\n",
    "            'popularity_order'\n",
    "        ],\n",
    "        'race_past_5_result_info':[\n",
    "            'race_id',\n",
    "            'bracket_num',\n",
    "            'horse_num',\n",
    "            'past_1_order',\n",
    "            'past_2_order',\n",
    "            'past_3_order',\n",
    "            'past_4_order',\n",
    "            'past_5_order'\n",
    "        ]\n",
    "    },\n",
    "\n",
    "    # col names in dataframe\n",
    "    'DATAFRAME_COL_NAMES': {\n",
    "\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race prior table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_num_str(num):\n",
    "    num_str = str(num) if num >= 10 else '0' + str(num)\n",
    "    return num_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race):\n",
    "    race_id = str(event_year) + _get_num_str(event_place) + _get_num_str(event_month) + _get_num_str(event_time) + _get_num_str(event_race)\n",
    "    target_url = parameters['URL_ABOUT_NETKEIBA']['RACE_TABLE'] + race_id\n",
    "    \n",
    "    return race_id, target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "def _is_the_race_id_existing_in_master(race_id):\n",
    "    query = \"\"\"\n",
    "        SELECT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id = \"{RACE_ID}\";\n",
    "    \"\"\".format(RACE_ID=race_id)\n",
    "    race_id_list_in_master = _fetchall_and_make_list_by(query)\n",
    "    if race_id_list_in_master is None:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_common_info(soup, race_id):\n",
    "    race_title = soup.find('div', class_='data_intro').find('h1').text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_coure = soup.find('div', class_='data_intro').find_all('p')[0].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    race_weather = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[0]\n",
    "    race_weather = re.search('天気：(.*)', race_weather).group(1)\n",
    "    \n",
    "    race_condition = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[1]\n",
    "    race_condition = re.search('馬場：(.*)', race_condition).group(1)\n",
    "    \n",
    "    starting_time = soup.find('div', class_='data_intro').find_all('p')[1].text.replace(u'\\xa0',u' ').split('/')[2]\n",
    "    starting_time = re.search('発走：(.*)', starting_time).group(1)\n",
    "    \n",
    "    race_date_info = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[0].text\n",
    "    race_year = re.split('/|\\(|\\)', race_date_info)[0]\n",
    "    race_month = re.split('/|\\(|\\)', race_date_info)[1]\n",
    "    race_date = re.split('/|\\(|\\)', race_date_info)[2]\n",
    "    race_dow = re.split('/|\\(|\\)', race_date_info)[3]\n",
    "    \n",
    "    race_info_1 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[1].text.replace(u'\\xa0',u' ')\n",
    "    race_info_2 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[2].text.replace(u'\\xa0',u' ')\n",
    "    race_info_3 = soup.find('div', class_='data_intro').find('div', class_='race_otherdata').find_all('p')[3].text.replace(u'\\xa0',u' ')\n",
    "    \n",
    "    return race_id, race_title, race_coure, race_weather, race_condition, race_year, race_month, race_date, race_dow, starting_time, race_info_1, race_info_2, race_info_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_table(soup, race_id):\n",
    "    this_race_table_info = []\n",
    "    \n",
    "    table_length = len(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')) \n",
    "    for row in range(3, table_length):\n",
    "        bracket_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[0].text)\n",
    "        horse_num = int(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[1].text)\n",
    "        horse_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[3].find('a').text\n",
    "        sex_and_age = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[4].text\n",
    "        horse_age = int(re.sub(\"\\\\D\", \"\", sex_and_age))\n",
    "        horse_sex = re.match('[0-9a-zA-Zあ-んア-ン一-鿐]', sex_and_age).group()\n",
    "        weight_penalty = float(soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[5].text)\n",
    "        jockey_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].text\n",
    "        href_to_jockey = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[6].find('a').attrs['href']\n",
    "        owner_name = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        href_to_owner = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[7].find('a').attrs['href']\n",
    "        horse_weight_info = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        if horse_weight_info != '':\n",
    "            horse_weight = int(re.split('\\(|\\)', horse_weight_info)[0])\n",
    "            horse_weight_increment = re.split('\\(|\\)', horse_weight_info)[1]\n",
    "        else:\n",
    "            horse_weight = ''\n",
    "            horse_weight_increment = ''\n",
    "\n",
    "        win_odds = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[9].text\n",
    "        popularity_order = soup.find('table', class_='race_table_old nk_tb_common').find_all('tr')[row].find_all('td')[10].text\n",
    "        \n",
    "        this_race_table_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            horse_name,\n",
    "            horse_age,\n",
    "            horse_sex,\n",
    "            weight_penalty,\n",
    "            jockey_name,\n",
    "            href_to_jockey,\n",
    "            owner_name,\n",
    "            href_to_owner,\n",
    "            horse_weight,\n",
    "            horse_weight_increment,\n",
    "            win_odds,\n",
    "            popularity_order\n",
    "        ])\n",
    "        \n",
    "    return this_race_table_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _execute_query(query):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        cursor.close()\n",
    "        con.commit()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# def _truncate_target_rows(race_id):\n",
    "#     queries = [\n",
    "#         'TRUNCATE TABLE race_master WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id),\n",
    "#         'TRUNCATE TABLE race_table_info WHERE race_id = \"{RACE_ID}\";'.format(RACE_ID=race_id)\n",
    "#     ]\n",
    "#     for query in queries:\n",
    "#         print(query)\n",
    "#         _execute_query(query)\n",
    "\n",
    "def _bulk_insert(insert_list, target_table_name, insert_col_names):\n",
    "    try:\n",
    "        bi = BulkInsert(con)\n",
    "        bi.execute(insert_data=insert_list, target_table=target_table_name, col_names=insert_col_names)\n",
    "    except TypeError as e:\n",
    "        print(e)\n",
    "        raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_insert_race_master_and_table_info():\n",
    "    for event_year in range(2019, 2020):\n",
    "        for event_place in range(1,2):\n",
    "            for event_month in range(1, 2):\n",
    "                for event_time in range(1, 2):\n",
    "                    for event_race in range(1, 2):\n",
    "                        race_master_list = []\n",
    "                        race_table_info_list = []\n",
    "                        race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)                    \n",
    "                        html = requests.get(target_url)\n",
    "                        html.encoding = 'EUC-JP'\n",
    "                        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "                        if not soup.find_all('table', attrs={'class', 'race_table_old nk_tb_common'}):\n",
    "                            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "                            continue\n",
    "\n",
    "                        print('Target URL to requests: ', target_url)\n",
    "                        try:\n",
    "                            race_master_list.append(_extract_common_info(soup, race_id))\n",
    "                        except AttributeError:\n",
    "                            print('\\t This URL has no master info')\n",
    "                        race_table_info_list = race_table_info_list + _extract_race_table(soup, race_id)\n",
    "                        _bulk_insert(race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])\n",
    "                        _bulk_insert(race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        \n",
    "                        \n",
    "                        time.sleep(1)\n",
    "                \n",
    "#     return race_master_list, race_table_info_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# race_master_list, race_table_info_list = get_and_insert_race_master_and_table_info()\n",
    "get_and_insert_race_master_and_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(race_master_list).shape)\n",
    "# print(pd.DataFrame(race_table_info_list).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(race_master_list).to_csv('race_master.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.DataFrame(race_table_info_list).to_csv('race_table_info_list.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "event_year = 2019\n",
    "event_place = 8\n",
    "event_month =5\n",
    "event_time = 4\n",
    "event_race = 11\n",
    "\n",
    "race_id, target_url = make_race_id_and_target_url(event_year, event_place, event_month, event_time, event_race)\n",
    "print(race_id)\n",
    "print('Target URL to requests: ', target_url)\n",
    "\n",
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    race_master_list = _extract_common_info(soup, race_id)\n",
    "    race_table_info_list = _extract_race_table(soup, race_id)\n",
    "except (AttributeError, ValueError):\n",
    "    print('\\t This URL has no master info')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_master_list, 'race_master', parameters['TABLE_COL_NAMES']['race_master'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _bulk_insert(race_id, race_table_info_list, 'race_table_info', parameters['TABLE_COL_NAMES']['race_table_info'])                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fetchall_and_make_list_by(query, con):\n",
    "    try:\n",
    "        cursor = con.cursor()\n",
    "        cursor.execute(query)\n",
    "        fetch_result = cursor.fetchall()\n",
    "        fetch_result_list = [item for item in fetch_result]\n",
    "        cursor.close()\n",
    "        return fetch_result_list\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_target_url_about_race_result(race_id):\n",
    "        return parameters['URL_ABOUT_NETKEIBA']['RACE_RESULT'].format(RACE_ID=race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_ids_in_master():\n",
    "    query = \"\"\"\n",
    "        SELECT DISTINCT race_id \n",
    "        FROM race_master\n",
    "        WHERE race_id NOT IN (SELECT DISTINCT race_id FROM race_result_info);\n",
    "    \"\"\"\n",
    "    result = _fetchall_and_make_list_by(query, con)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_result_info(soup, race_id):\n",
    "    this_race_result_info = []\n",
    "    table_length = len(soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr'))\n",
    "    \n",
    "    for row in range(1, table_length):\n",
    "        arrrival_order  = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[0].text\n",
    "        bracket_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[1].text\n",
    "        horse_num = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[2].text\n",
    "        arrival_time = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[7].text\n",
    "        arrival_diff = soup.find('table', class_='race_table_01 nk_tb_common').find_all('tr')[row].find_all('td')[8].text\n",
    "        \n",
    "        this_race_result_info.append([\n",
    "            race_id,\n",
    "            bracket_num,\n",
    "            horse_num,\n",
    "            arrival_time,\n",
    "            arrival_diff,\n",
    "            arrrival_order\n",
    "        ])\n",
    "\n",
    "    return this_race_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_race_refund_info(soup, race_id):\n",
    "    empty_refund_list = []\n",
    "    refund_table_list = soup.find('dd', class_='fc').find_all('tr')\n",
    "    for i in range(len(refund_table_list)):\n",
    "        refund_table = refund_table_list[i]\n",
    "        refund_type = refund_table.find('th').text\n",
    "\n",
    "        if refund_type == '単勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '単勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '複勝':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text[:2]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '複勝', 2,  \n",
    "                 int(refund_table.find_all('td')[0].text[2:4]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            try:\n",
    "                empty_refund_list.append(\n",
    "                    [race_id, '複勝', 3, \n",
    "                     int(refund_table.find_all('td')[0].text[4:6]),\n",
    "                     int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                     int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "                )\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        elif refund_type == '枠連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '枠連', 1,  \n",
    "                 int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                 int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                 int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "\n",
    "        elif refund_type == '馬連':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))],\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬連', 1,  \n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == 'ワイド':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[:2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 1,  \n",
    "                int(refund_table.find_all('td')[0].text[5:7]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[7:9]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 2,  \n",
    "                int(refund_table.find_all('td')[0].text[12:14]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[1].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[1])],            \n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[14:16]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, 'ワイド', 3,  \n",
    "                int(refund_table.find_all('td')[0].text[19:22]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[2].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[2].replace(',', ''))]\n",
    "            )   \n",
    "            \n",
    "        elif refund_type == '馬単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '馬単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0])]             \n",
    "            )\n",
    "            \n",
    "        elif refund_type == '三連複':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連複', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('-')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))] \n",
    "            )       \n",
    "            \n",
    "        elif refund_type == '三連単':\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[0]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )\n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[1]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )        \n",
    "            empty_refund_list.append(\n",
    "                [race_id, '三連単', 1,\n",
    "                int(refund_table.find_all('td')[0].text.split('→')[2]),\n",
    "                int(refund_table.find_all('td')[1].text.split('円')[0].replace(',', '')),\n",
    "                int(refund_table.find_all('td')[2].text.split('人気')[0].replace(',', ''))]\n",
    "            )                \n",
    "\n",
    "    return empty_refund_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_race_result_info():\n",
    "    existing_race_ids_in_master = _extract_race_ids_in_master()\n",
    "    \n",
    "    for id_idx in range(len(existing_race_ids_in_master)):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = _make_target_url_about_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        race_result_info_list = _extract_race_result_info(soup, race_id)\n",
    "        race_refund_info_list = _extract_race_refund_info(soup, race_id)\n",
    "        \n",
    "        _bulk_insert(race_result_info_list, 'race_result_info', parameters['TABLE_COL_NAMES']['race_result_info'])\n",
    "        _bulk_insert(race_refund_info_list, 'race_refund_info', parameters['TABLE_COL_NAMES']['race_refund_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_race_result_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get info about past 5 race result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_target_url_about_past_5_race_result(race_id):\n",
    "    return parameters['URL_ABOUT_NETKEIBA']['RACE_PAST5_RESULT'].format(RACE_ID=race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _extract_past_5_race_result(soup, race_id):\n",
    "    this_race_past5_result_info = []\n",
    "    table_element = soup.find('table', class_='race_table_01 nk_tb_common shutuba_table').find_all('tr')\n",
    "    table_length = len(table_element)\n",
    "\n",
    "    for row in range(1, table_length):\n",
    "        bracket_num = table_element[row].find_all('td')[0].text\n",
    "        horse_num = table_element[row].find_all('td')[1].text\n",
    "\n",
    "        order_list = []\n",
    "        for col in range(6, 11):\n",
    "            try:\n",
    "                order = table_element[row].find_all('td')[col].find('span', class_='order').text\n",
    "            except AttributeError:\n",
    "                order = ''\n",
    "            order_list += [order]\n",
    "\n",
    "        this_race_past5_result_info.append([race_id, bracket_num, horse_num] + order_list)\n",
    "    return this_race_past5_result_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_past_5_race_result_info():\n",
    "    existing_race_ids_in_master = _extract_race_ids_in_master()\n",
    "    \n",
    "    for id_idx in range(len(existing_race_ids_in_master)):\n",
    "        race_id = existing_race_ids_in_master[id_idx][0]\n",
    "        target_url = _make_target_url_about_race_result(race_id)\n",
    "        \n",
    "        html = requests.get(target_url)\n",
    "        html.encoding = 'EUC-JP'\n",
    "        soup = BeautifulSoup(html.text, 'html.parser')\n",
    "\n",
    "        if not soup.find_all('table', attrs={'class', 'race_table_01 nk_tb_common shutuba_table'}):\n",
    "            print('Target URL to requests ', target_url, 'does not exist.')\n",
    "            break\n",
    "\n",
    "        print('Target URL to requests: ', target_url)\n",
    "        race_past5_result_info_list = _extract_past_5_race_result(soup, race_id)        \n",
    "        _bulk_insert(race_past5_result_info_list, 'race_past_5_result_info', \n",
    "                     parameters['TABLE_COL_NAMES']['race_past_5_result_info'])                        \n",
    "\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "existing_race_ids_in_master = _extract_race_ids_in_master()\n",
    "existing_race_ids_in_master[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_idx = 0\n",
    "race_id = existing_race_ids_in_master[id_idx][0]\n",
    "race_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_url = _make_target_url_about_past_5_race_result(race_id)\n",
    "target_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = requests.get(target_url)\n",
    "html.encoding = 'EUC-JP'\n",
    "soup = BeautifulSoup(html.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "_extract_past_5_race_result(soup, race_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
